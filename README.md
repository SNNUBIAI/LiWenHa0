# LiWenHa0
李文浩的工作记录
# 学习记录

- 学习attention机制，其中self-attention和multi-head attention机制，masked attention机制及位置编码，学习Transformer基本流程Encoders和Decoders。 
- 了解Transforms如何运作，及定义Multi-headattention和mask编码机制，前向传递函数FFN，Encoder和Decoder一些列构成Transforms的函数定义
- 纤维追踪及MRtrix教程https://liaopan.github.io/datasets/
- MRI知识问答网站https://mriquestions.com/index.html
